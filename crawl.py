from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

# Thi·∫øt l·∫≠p tr√¨nh duy·ªát Firefox
firefox_options = webdriver.FirefoxOptions()
firefox_options.set_preference("browser.download.folderList", 2)
firefox_options.set_preference("browser.helperApps.alwaysAsk.force", False)
firefox_options.set_preference("browser.download.manager.showWhenStarting", False)
firefox_options.set_preference("browser.download.dir", 'D:\\crawl_\\Doc_xls')
firefox_options.set_preference("plugin.disable_full_page_plugin_for_types", "application/pdf")
firefox_options.set_preference("pdfjs.disabled", True)
firefox_options.set_preference("browser.helperApps.neverAsk.saveToDisk", "application/pdf")

def crawl_documents():
    url = "https://vanban.chinhphu.vn/?pageid=41852&mode=0"
    driver = webdriver.Firefox(options=firefox_options)
    driver.get(url)
    
    wait = WebDriverWait(driver, 10)

    # 1Ô∏è‚É£ Ch·ªçn "B·ªô N·ªôi V·ª•"
    select_element = wait.until(EC.presence_of_element_located((By.ID, "ctrl_191017_163_drdDocOrg")))
    select = Select(select_element)
    select.select_by_value("23")
    print("‚úÖ ƒê√£ ch·ªçn B·ªô N·ªôi V·ª•")

    # 2Ô∏è‚É£ Ch·ªçn hi·ªÉn th·ªã 500 k·∫øt qu·∫£
    record_select_element = wait.until(EC.presence_of_element_located((By.ID, "ctrl_191017_163_drdRecordPerPage")))
    record_select = Select(record_select_element)
    record_select.select_by_value("500")
    print("‚úÖ ƒê√£ ch·ªçn hi·ªÉn th·ªã 500 k·∫øt qu·∫£")

    # 3Ô∏è‚É£ Nh·∫•n n√∫t t√¨m ki·∫øm
    search_button = wait.until(EC.element_to_be_clickable((By.ID, "ctrl_191017_163_btnSearch")))
    search_button.click()
    print("‚úÖ ƒê√£ nh·∫•n n√∫t t√¨m ki·∫øm")
    
    time.sleep(5)  # ƒê·ª£i trang t·∫£i k·∫øt qu·∫£

    all_links = []
    page_count = 1

    while True:
        print(f"üîç ƒêang crawl trang {page_count}...")

        # Cu·ªôn xu·ªëng cu·ªëi trang ƒë·ªÉ Selenium th·∫•y n·ªôi dung
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1)

        # L·∫•y danh s√°ch vƒÉn b·∫£n
        try:
            table = driver.find_element(By.CLASS_NAME, "table.search-result")
            rows = table.find_elements(By.TAG_NAME, "tr")
        except:
            print("‚ùå Kh√¥ng t√¨m th·∫•y b·∫£ng k·∫øt qu·∫£ t√¨m ki·∫øm!")
            break

        for row in rows:
            link_element = row.find_elements(By.TAG_NAME, "a")
            if link_element:
                link = link_element[0].get_attribute("href")
                all_links.append(link)

        # L∆∞u l·∫°i HTML c·ªßa trang cu·ªëi c√πng ƒë·ªÉ debug
        with open("last_page.html", "w", encoding="utf-8") as f:
            f.write(driver.page_source)

        # 1Ô∏è‚É£ T√¨m `Page$k+1` tr∆∞·ªõc
        try:
            next_page = driver.find_element(By.XPATH, f"//td/a[contains(@href, \"Page${page_count + 1}\")]")
            print(f"‚úÖ Nh·∫•n v√†o trang {page_count + 1}")
            driver.execute_script("arguments[0].click();", next_page)
            page_count += 1
            time.sleep(3)
            continue  # N·∫øu t√¨m th·∫•y `Page$k+1`, ti·∫øp t·ª•c v√≤ng l·∫∑p
        except:
            next_page = None

        # 2Ô∏è‚É£ N·∫øu kh√¥ng t√¨m th·∫•y `Page$k+1`, th·ª≠ m·ªü r·ªông danh s√°ch trang b·∫±ng c√°ch b·∫•m "..."
        try:
            expand_page = driver.find_element(By.XPATH, "//td/a[contains(text(), '...')]")
            print("üîÑ M·ªü r·ªông danh s√°ch trang b·∫±ng c√°ch nh·∫•n '...'")
            driver.execute_script("arguments[0].click();", expand_page)
            time.sleep(3)

            # Sau khi m·ªü r·ªông, ki·ªÉm tra l·∫°i `Page$k+1`
            try:
                next_page = driver.find_element(By.XPATH, f"//td/a[contains(@href, \"Page${page_count + 1}\")]")
                print(f"‚úÖ Nh·∫•n v√†o trang {page_count + 1} sau khi m·ªü r·ªông")
                driver.execute_script("arguments[0].click();", next_page)
                page_count += 1
                time.sleep(3)
                continue
            except:
                print("‚ùå Kh√¥ng t√¨m th·∫•y trang m·ªõi sau khi m·ªü r·ªông.")
                break
        except:
            print("‚úÖ Kh√¥ng c√≤n trang ti·∫øp theo. K·∫øt th√∫c crawl.")
            break

    driver.quit()

    # L∆∞u danh s√°ch vƒÉn b·∫£n v√†o file
    with open("documents.txt", "w", encoding="utf-8") as f:
        for link in all_links:
            f.write(link + "\n")

    print(f"üìú T·ªïng s·ªë vƒÉn b·∫£n l·∫•y ƒë∆∞·ª£c: {len(all_links)}")
    return all_links

# Ch·∫°y crawl
document_links = crawl_documents()
